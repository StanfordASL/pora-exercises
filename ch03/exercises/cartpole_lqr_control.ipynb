{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Cartpole LQR Control\n",
    "In this problem we consider controlling a cart-pole system, which consists of a \"cart\" that can travel linearly along a one-dimensional track, and has a pendulum attached to it.\n",
    "The objective is to control the cart position to stablize the pendulum about its \"inverted\" position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from cartpole_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Linearizing the Cartpole Dynamics\n",
    "Implement the function `compute_lti_matrices` to compute the linear time-invariant (LTI) system matrices $A$ and $B$ for the cart-pole system about the upright equilibrium state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lti_matrices(cartpole: CartPole, dt: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the linearized dynamics matrices A and B of the LTI system\n",
    "\n",
    "    Args:\n",
    "        cartpole: CartPole object storing params\n",
    "        dt: time step\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: Tuple of:\n",
    "            np.ndarray: The A (dynamics) matrix, shape (n, n)\n",
    "            np.ndarray: The B (controls) matrix, shape (n, m)\n",
    "    \"\"\"\n",
    "    mp, mc, L, g = cartpole.mp, cartpole.mc, cartpole.L, cartpole.g\n",
    "    ############################## Code starts here ##############################\n",
    "    raise NotImplementedError()\n",
    "    ############################## Code ends here ##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2: Implement Discrete-time Riccati Equations\n",
    "Implement the function `discreteLQR.solve` to solve the LQR problem by implementing the Riccati recursion to approximate the optimal gain matrix $K_\\infty$ for the linearized and discrete-time cart-pole system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discreteLQR(object):\n",
    "    def __init__(self, Q, R, eps=1e-4, max_iters=1000):\n",
    "        \"\"\"\n",
    "        Initialize the discrete-time LQR problem with cost function matrices.\n",
    "    \n",
    "        Args:\n",
    "            Q (np.ndarray): State cost matrix, shape (n, n)\n",
    "            R (np.ndarray): Control cost matrix, shape (m, m)\n",
    "            eps: termination threshold for Riccati recursion\n",
    "            max_iters: maximum number of Riccati recursion iterations\n",
    "        \"\"\"\n",
    "        if max_iters <= 1:\n",
    "            raise ValueError(\"Argument `max_iters` must be at least 1.\")\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "        self.eps = eps\n",
    "        self.max_iters = max_iters\n",
    "        self.n = Q.shape[0]  # state dimension\n",
    "        self.m = R.shape[0]  # control dimension\n",
    "        \n",
    "        # Initialize gain matrix\n",
    "        self.K = np.zeros((self.m, self.n))\n",
    "\n",
    "        # Initialize the reference points\n",
    "        self.u_ref = np.zeros(self.m)\n",
    "        self.s_ref = np.zeros(self.n)\n",
    "\n",
    "    def solve(\n",
    "        self, A: np.ndarray, B: np.ndarray, s_ref: np.ndarray, u_ref: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute the gain matrix K through Ricatti recursion. Stores the gain matrix\n",
    "        in self.K and returns it.\n",
    "    \n",
    "        Args:\n",
    "            A (np.ndarray): Dynamics matrix, shape (n, n)\n",
    "            B (np.ndarray): Controls matrix, shape (n, m)\n",
    "            s_ref (np.ndarray): Reference trajectory that A, B are linearized about, shape(num_timesteps, n)\n",
    "                                Note, every point of the reference trajectory must have the same A, B linearization.\n",
    "            u_ref (np.ndarray): Reference control that A, B are linearized about, shape(m,)\n",
    "    \n",
    "        Returns:\n",
    "            np.ndarray: Gain matrix K, shape (m, n)\n",
    "        \"\"\"\n",
    "        self.u_ref = u_ref\n",
    "        self.s_ref = s_ref\n",
    "        P_prev = np.zeros((self.n, self.n))  # initialization\n",
    "        converged = False\n",
    "        for i in range(self.max_iters):\n",
    "            ############################## Code starts here ##############################\n",
    "            raise NotImplementedError()\n",
    "            ############################## Code ends here ##############################\n",
    "        if not converged:\n",
    "            raise RuntimeError(\"Ricatti recursion did not converge!\")\n",
    "        self.K = K\n",
    "        return K\n",
    "    \n",
    "    def compute_control(self, k: int, s: np.ndarray, closed_loop: bool=True):\n",
    "        \"\"\"\n",
    "        Compute the control value for the LQR controller. If `closed_loop` is false\n",
    "        just return the open loop u_ref value.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        k: current time step\n",
    "        s: current state\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        u: control value to apply\n",
    "        \"\"\"\n",
    "        return self.K @ (s - self.s_ref[k]) + self.u_ref if closed_loop else self.u_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.3: Simulate Stabilized Cartpole\n",
    "Run the code below to simulate the stabilized cartpole with an LQR feedback controller defined using the functions you implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for the cart-pole system\n",
    "mp = 2.0  # pendulum mass\n",
    "mc = 10.0  # cart mass\n",
    "L = 1.0  # pendulum length\n",
    "g = 9.81  # gravitational acceleration\n",
    "cartpole = CartPole(mp, mc, L, g)\n",
    "\n",
    "# Compute discrete LTI model with 10Hz sampling rate\n",
    "dt = 0.1\n",
    "t = np.arange(0.0, 30.0, dt)\n",
    "A, B = compute_lti_matrices(cartpole, dt)\n",
    "\n",
    "# Compute LQR gain matrix\n",
    "n = 4\n",
    "m = 1\n",
    "Q = np.eye(n)  # state cost matrix\n",
    "R = np.eye(m)  # control cost matrix\n",
    "lqr = discreteLQR(Q, R)\n",
    "s_ref = np.array([0.0, np.pi, 0.0, 0.0]) * np.ones((t.size, 1)) # stablize at equilibrium\n",
    "u_ref = np.array([0.0])\n",
    "lqr.solve(A, B, s_ref, u_ref)\n",
    "\n",
    "# Simulate and plot results\n",
    "s0 = np.array([0.0, 3 * np.pi / 4, 0.0, 0.0])\n",
    "s, u = simulate_cartpole(cartpole, t, s0, lqr)\n",
    "plot_state_and_control_history(s, u, t, lqr.s_ref, \"cartpole_balance\")\n",
    "animate_cartpole(t, s[:, 0], s[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.4: Use LQR to Track Time-varying Reference Trajectory\n",
    "Implement the function `reference` below to generate a time-varying reference trajectory that keeps the pendulum upright while moving the cart's linear position according to $\\bar{x}(t) = a \\sin(2\\pi t/ T)$. Then, run the code below to see the simulated results. Try playing with the state penalty matrix $Q$ to see if you can improve the tracking error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference(t: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the reference state (s_bar) at time t\n",
    "\n",
    "    Args:\n",
    "        t (float): Evaluation time\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Reference state, shape (n,)\n",
    "    \"\"\"\n",
    "    a = 10.0  # Amplitude\n",
    "    T = 10.0  # Period\n",
    "\n",
    "    ############################## Code starts here ##############################\n",
    "    raise NotImplementedError()\n",
    "    ############################## Code ends here ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for the cart-pole system\n",
    "mp = 2.0  # pendulum mass\n",
    "mc = 10.0  # cart mass\n",
    "L = 1.0  # pendulum length\n",
    "g = 9.81  # gravitational acceleration\n",
    "cartpole = CartPole(mp, mc, L, g)\n",
    "\n",
    "# Compute discrete LTI model with 10Hz sampling rate\n",
    "dt = 0.1\n",
    "A, B = compute_lti_matrices(cartpole, dt)\n",
    "\n",
    "# Compute LQR gain matrix\n",
    "n = 4\n",
    "m = 1\n",
    "Q = np.eye(n)  # state cost matrix\n",
    "R = np.eye(m)  # control cost matrix\n",
    "lqr = discreteLQR(Q, R)\n",
    "s_ref = np.array([reference(ti) for ti in t])\n",
    "u_ref = np.array([0.0])\n",
    "lqr.solve(A, B, s_ref, u_ref)\n",
    "\n",
    "# Simulate with time-varying reference and plot results\n",
    "s0 = np.array([0.0, np.pi, 0.0, 0.0])\n",
    "s, u = simulate_cartpole(cartpole, t, s0, lqr)\n",
    "plot_state_and_control_history(s, u, t, lqr.s_ref, \"cartpole_balance_tv\")\n",
    "animate_cartpole(t, s[:, 0], s[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
