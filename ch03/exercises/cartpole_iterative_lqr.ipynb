{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Cartpole iLQR Control\n",
    "In this problem we consider controlling a cart-pole system, which consists of a \"cart\" that can travel linearly along a one-dimensional track, and has a pendulum attached to it.\n",
    "The objective is to implement a controller to solve the \"swing up\" problem to bring the pendulum from the downard hanging position to a stabilized upright position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "from cartpole_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.1: Linearizing the Cartpole Dynamics\n",
    "Implement the function `linearize` to linearize the function `f(s,u)` about the point `(s,u)` using JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize(f, s, u):\n",
    "    \"\"\"\n",
    "    Linearize the function `f(s, u)` around `(s, u)`.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    f : callable\n",
    "        A nonlinear function with call signature `f(s, u)`.\n",
    "    s : numpy.ndarray\n",
    "        The state (1-D).\n",
    "    u : numpy.ndarray\n",
    "        The control input (1-D).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : numpy.ndarray\n",
    "        The Jacobian of `f` at `(s, u)`, with respect to `s`.\n",
    "    B : numpy.ndarray\n",
    "        The Jacobian of `f` at `(s, u)`, with respect to `u`.\n",
    "    \"\"\"\n",
    "    ############################## Code starts here ##############################\n",
    "    # Use JAX to compute the matrices A and B in one line.\n",
    "    raise NotImplementedError()\n",
    "    ############################## Code ends here ##############################\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.3 and 4.4: Implement iLQR\n",
    "Implement the function `discreteIterativeLQR.solve` below to compute the iLQR controller gain matrices and offset terms. Note here we are referring to the gain matrix as $Y$ and the offset term as $y$ to avoid confusion with respect to the time step variable $k$. Concretely, the controller we are looking to define is of the form:\n",
    "\\begin{equation}\n",
    "    u_k = \\bar u_k - y_k - Y_k(s_k - \\bar s_k),\n",
    "\\end{equation}\n",
    "\n",
    "Then, implement the function `discreteIterativeLQR.compute_control` to compute the control value based on either the open or closed-loop case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discreteIterativeLQR(object):\n",
    "    def __init__(self, N, Q, R, QN, eps=1e-3, max_iters=1000):\n",
    "        \"\"\"\n",
    "        Initialize the discrete-time iLQR problem with cost function and horizon.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        N : int\n",
    "            The time horizon of the LQR cost function.\n",
    "        Q : numpy.ndarray\n",
    "            The state cost matrix (2-D).\n",
    "        R : numpy.ndarray\n",
    "            The control cost matrix (2-D).\n",
    "        QN : numpy.ndarray\n",
    "            The terminal state cost matrix (2-D).\n",
    "        eps : float, optional\n",
    "            Termination threshold for iLQR.\n",
    "        max_iters : int, optional\n",
    "            Maximum number of iLQR iterations.\n",
    "        \"\"\"\n",
    "        if max_iters <= 1:\n",
    "            raise ValueError(\"Argument `max_iters` must be at least 1.\")\n",
    "        self.N = N\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "        self.QN = QN\n",
    "        self.eps = eps\n",
    "        self.max_iters = max_iters\n",
    "        self.n = Q.shape[0]  # state dimension\n",
    "        self.m = R.shape[0]  # control dimension\n",
    "        \n",
    "        # Initialize gains `Y` and offsets `y` for the policy\n",
    "        self.Y = np.zeros((self.N, self.m, self.n))\n",
    "        self.y = np.zeros((self.N, self.m))\n",
    "\n",
    "        # Initialize the nominal trajectory `(s_bar, u_bar`),\n",
    "        self.u_bar = np.zeros((self.N, self.m))\n",
    "        self.s_bar = np.zeros((self.N + 1, self.n))\n",
    "\n",
    "    def solve(self, f, s0, s_goal):\n",
    "        \"\"\"\n",
    "        Compute the iLQR set-point tracking solution for given discrete-time dynamics and start\n",
    "        goal states. Sets the s_bar, u_bar, Y, and y member variables and also returns them.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        f : callable\n",
    "            A function describing the discrete-time dynamics, such that\n",
    "            `s[k+1] = f(s[k], u[k])`.\n",
    "        s0 : numpy.ndarray\n",
    "            The initial state (1-D).\n",
    "        s_goal : numpy.ndarray\n",
    "            The goal state (1-D).\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        s_bar : numpy.ndarray\n",
    "            A 2-D array where `s_bar[k]` is the nominal state at time step `k`,\n",
    "            for `k = 0, 1, ..., N-1`\n",
    "        u_bar : numpy.ndarray\n",
    "            A 2-D array where `u_bar[k]` is the nominal control at time step `k`,\n",
    "            for `k = 0, 1, ..., N-1`\n",
    "        Y : numpy.ndarray\n",
    "            A 3-D array where `Y[k]` is the matrix gain term of the iLQR control\n",
    "            law at time step `k`, for `k = 0, 1, ..., N-1`\n",
    "        y : numpy.ndarray\n",
    "            A 2-D array where `y[k]` is the offset term of the iLQR control law\n",
    "            at time step `k`, for `k = 0, 1, ..., N-1`\n",
    "        \"\"\"\n",
    "        n, m, N = self.n, self.m, self.N\n",
    "        # Initialize gains `Y` and offsets `y` for the policy\n",
    "        Y = np.zeros((N, m, n))\n",
    "        y = np.zeros((N, m))\n",
    "    \n",
    "        # Initialize the nominal trajectory `(s_bar, u_bar`), and the\n",
    "        # deviations `(ds, du)`\n",
    "        u_bar = np.zeros((N, m))\n",
    "        s_bar = np.zeros((N + 1, n))\n",
    "        s_bar[0] = s0\n",
    "        for k in range(N):\n",
    "            s_bar[k + 1] = f(s_bar[k], u_bar[k])\n",
    "        ds = np.zeros((N + 1, n))\n",
    "        du = np.zeros((N, m))\n",
    "    \n",
    "        # iLQR loop\n",
    "        converged = False\n",
    "        for _ in range(self.max_iters):\n",
    "            # Linearize the dynamics at each step `k` of `(s_bar, u_bar)`\n",
    "            A, B = jax.vmap(linearize, in_axes=(None, 0, 0))(f, s_bar[:-1], u_bar)\n",
    "            A, B = np.array(A), np.array(B)\n",
    "    \n",
    "            ############################## Code starts here ##############################\n",
    "            # Update `Y`, `y`, `ds`, `du`, `s_bar`, and `u_bar`.\n",
    "            raise NotImplementedError()\n",
    "            ############################## Code ends here ##############################\n",
    "    \n",
    "            if np.max(np.abs(du)) < self.eps:\n",
    "                converged = True\n",
    "                break\n",
    "        if not converged:\n",
    "            raise RuntimeError(\"iLQR did not converge!\")\n",
    "        self.s_bar = s_bar\n",
    "        self.u_bar = u_bar\n",
    "        self.Y = Y\n",
    "        self.y = y\n",
    "        return s_bar, u_bar, Y, y\n",
    "\n",
    "    def compute_control(self, k: int, s: np.ndarray, closed_loop: bool=True):\n",
    "        \"\"\"\n",
    "        Compute the control value for the iLQR controller. If `closed_loop` is false\n",
    "        just return the open loop u_bar value.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        k: current time step\n",
    "        s: current state\n",
    "        closed_loop: whether to run in closed-loop or not\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        u: control value to apply\n",
    "        \"\"\"\n",
    "        ############################## Code starts here ##############################\n",
    "        raise NotImplementedError()\n",
    "        ############################## Code ends here ##############################\n",
    "        return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the code below to simulate the iLQR controller in both open-loop and closed-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for the cart-pole system\n",
    "mp = 2.0  # pendulum mass\n",
    "mc = 10.0  # cart mass\n",
    "L = 1.0  # pendulum length\n",
    "g = 9.81  # gravitational acceleration\n",
    "cartpole = CartPole(mp, mc, L, g)\n",
    "\n",
    "# Define problem set up constants\n",
    "s0 = np.array([0.0, 0.0, 0.0, 0.0])  # initial state\n",
    "s_goal = np.array([0.0, np.pi, 0.0, 0.0])  # goal state\n",
    "T = 10.0  # simulation time\n",
    "dt = 0.1  # sampling time\n",
    "\n",
    "# Define iLQR Problem\n",
    "n = 4  # state dimension\n",
    "m = 1  # control dimension\n",
    "t = np.arange(0.0, T, dt)\n",
    "N = t.size - 1\n",
    "Q = np.diag(np.array([10.0, 10.0, 2.0, 2.0]))  # state cost matrix\n",
    "R = 1e-2 * np.eye(m)  # control cost matrix\n",
    "QN = 1e2 * np.eye(n)  # terminal state cost matrix\n",
    "ilqr = discreteIterativeLQR(N, Q, R, QN)\n",
    "\n",
    "# Initialize continuous-time and discretized dynamics\n",
    "f = jax.jit(cartpole_dynamics, static_argnums=(2,))\n",
    "fd = jax.jit(lambda s, u, dt=dt: s + dt * f(s, u, cartpole))\n",
    "\n",
    "# Compute the iLQR solution with the discretized dynamics\n",
    "print(\"Computing iLQR solution ... \", end=\"\", flush=True)\n",
    "start = time.time()\n",
    "ilqr.solve(fd, s0, s_goal)\n",
    "print(\"done! ({:.2f} s)\".format(time.time() - start), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate on the true continuous-time system and plot results\n",
    "closed_loop = False  # open-loop\n",
    "s, u = simulate_cartpole(cartpole, t, s0, ilqr, closed_loop=closed_loop)\n",
    "plot_state_and_control_history(s, u, t, ilqr.s_bar, \"cartpole_swingup\")\n",
    "animate_cartpole(t, s[:, 0], s[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate on the true continuous-time system and plot results\n",
    "closed_loop = True  # closed-loop\n",
    "s, u = simulate_cartpole(cartpole, t, s0, ilqr, closed_loop=closed_loop)\n",
    "plot_state_and_control_history(s, u, t, ilqr.s_bar, \"cartpole_swingup\")\n",
    "animate_cartpole(t, s[:, 0], s[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
