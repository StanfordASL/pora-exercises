{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU4mONuMOIjr"
   },
   "source": [
    "# Exercise 1: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1: Load the CIFAR-10 \n",
    "Run the code below to load the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) and visualize some of the images in the dataset. The images in this dataset are 32 x 32 color images of the following objects: \\\n",
    "`classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size for the train and test datasets\n",
    "batch_size = 64\n",
    "\n",
    "# Load CIFAR-10 dataset and normalize the RGB channels\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # normalize RGB channels\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Visualize some example images from the dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "def imshow(img, title=None):\n",
    "    img = img / 2 + 0.5  # unnormalize RGB channels\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "# Get a few random training images\n",
    "sample_images, sample_labels = next(iter(train_loader))\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "imshow(torchvision.utils.make_grid(sample_images[:8]))\n",
    "plt.title(\"Sample CIFAR-10 Images:\\n\" + \"  \".join(classes[sample_labels[j]] for j in range(8)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: Define Simple CNN Model and Train\n",
    "Implement the structure of the CNN in the class `SimpleCNN` below. Specifically:\n",
    "1. In `SimpleCNN.__init__`, define `self.conv_layers` and `self.fc_layers` for the convolution and fully-connected layers of the network.\n",
    "    1. Your model should have two convolution layers in `self.conv_layers`, each with ReLU activation after the convolution and a 2D max pooling to downsample. Use the parameter values given below to define each feature.\n",
    "    2. For `self.fc_layers`, you should flatten the output of the convolution layers, then have two linear layers separated by a ReLU activation. Use the parameter value given below to define the output size of the first linear layer. You must determine the size of the input for the first linear layer and the size of the final layer output.\n",
    "2. Implement the remaining code in the training loop to train your model using the `criterion` and `optimizer` provided.\n",
    "3. Run the code provided to evaluate the accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_kernel_size = 3\n",
    "        conv_padding = 1\n",
    "        max_pool_kernel_size = 2\n",
    "        max_pool_stride = 2\n",
    "        conv1_out_channels = 32\n",
    "        conv2_out_channels = 64\n",
    "        ########## Code starts here ##########\n",
    "        # Define self.conv_layers\n",
    "        # Hint: use nn.Sequential\n",
    "        \n",
    "        ########## Code ends here ############\n",
    "\n",
    "        hidden_layer_size = 256\n",
    "        ########## Code starts here ##########\n",
    "        # Define self.fc_layers\n",
    "        # Hint: use nn.Sequential\n",
    "        \n",
    "        ########## Code ends here ############\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the code below to train your model. You should see the epoch loss decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        ########## Code starts here ##########\n",
    "        \n",
    "        ########## Code ends here ############\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to estimate the accuracy of your trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model accuracy on test dataset\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3: Analyze Confusion Matrix\n",
    "Run the provided code to plot the confusion matrix from your test above. Take a look at the results, do you see any interesting patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp.plot(cmap='Blues', xticks_rotation=45, colorbar=False)\n",
    "plt.title(\"Confusion Matrix - CIFAR-10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the code provided below to revisit the sampled images from the dataset and see how your model predicted the image's classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display samples images from above\n",
    "sample_images = sample_images.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(sample_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "imshow(torchvision.utils.make_grid(sample_images[:8].cpu()))\n",
    "plt.title(\"Predicted: \" + \"  \".join(classes[predicted[j]] for j in range(8)) +\n",
    "          \"\\nTrue:      \" + \"  \".join(classes[sample_labels[j]] for j in range(8)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
